{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in this script, we implement our algorithm for matrix learning, following the proof\n",
    "#of the theorem... of ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JuMP \n",
    "using Mosek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementancion de las funciones<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# @param:weights : weights of the observed matrices. Sum of weights must be 1. and non-negative. the size is equal to the amount\n",
    "#of observed graphs.\n",
    "#@param: delta : size of the ball of the Wasserstein metric. delta > 0.\n",
    "#@param: A : cluster form of the data. A entries must be 0 or 1. \n",
    "#@param: B : vector of matrices containing the observations of the graph B. If X,Y are matrices, an array of matrices\n",
    "#is of the form Array[X,Y].\n",
    "#@param: n : the dimension of the matrices.\n",
    "#@param:N : number of observations.\n",
    "#The set over which the is problem is optimized is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       " El conjunto sobre el que optimizamos es:\n",
       "$ O = \\{\\lambda,S_1,..,S_N,Z^{1},..,Z^{N},C^{1},...,C^{N},W,W_1,W_2 \\}\\subseteq \\mathbb{R}\\times \\mathbb{R}^N\n",
       "\\times Sim^2(\\mathbb{R}^n)^N \\times Sim^2(\\mathbb{R}^n)^N \\times Sim^2(\\mathbb{R}^)^3\n",
       "$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"text/latex\",\"\"\" El conjunto sobre el que optimizamos es:\n",
    "\\$ O = \\\\{\\\\lambda,S_1,..,S_N,Z^{1},..,Z^{N},C^{1},...,C^{N},W,W_1,W_2 \\\\}\\\\subseteq \\\\mathbb{R}\\\\times \\\\mathbb{R}^N\n",
    "\\\\times Sim^2(\\\\mathbb{R}^n)^N \\\\times Sim^2(\\\\mathbb{R}^n)^N \\\\times Sim^2(\\\\mathbb{R}^)^3\n",
    "\\$\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learnError (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes the error of estimating the cluster structure of the observations by the matrix A.\n",
    "function learnError(weights,delta,A,B,n,N)\n",
    "    one =ones(n)\n",
    "    m = Model(solver=MosekSolver())\n",
    "    @variable(m,lambda>=0)\n",
    "     @variable(m,S[1:N])\n",
    "    @variable(m, W[1:n,1:n], Symmetric)\n",
    "    Z = [@variable(m, [1:n, 1:n], Symmetric) for p in 1:N]\n",
    "    C = [@variable(m, [1:n, 1:n], Symmetric) for p in 1:N]\n",
    "    @variable(m,W1[1:n,1:n])\n",
    "    @variable(m,W2[1:n,1:n])\n",
    "    #Constraints for Z\n",
    "    [@constraint(m, -Z[p][k,l] <= A[k,l]-B[p][k,l]) for p in 1:N for k in 1:n for l in 1:n]\n",
    "    [@constraint(m,  A[k,l]-B[p][k,l]<=Z[p][k,l]) for p in 1:N for k in 1:n for l in 1:n]\n",
    "    #Constraints for C \n",
    "    [@constraint(m,C[p][k,l]>=0) for p in 1:N for k in 1:n for l in 1:n]\n",
    "    [@constraint(m, prod(C[p],n)<=S[p]-trace((2*A-one*one'-W)'*B[p])) for p in 1:N]\n",
    "    [@constraint(m,-C[p][k,l]<=2*A[k,l]-1-W[k,l]) for p in 1:N for k in 1:n for l in 1:n]\n",
    "    #Constraints for W\n",
    "    @SDconstraint(m,[W1 W;W W2]>=0)\n",
    "    @constraint(m,trace(W1)+trace(W2)<=2*lambda)\n",
    "    #Objective function, calls the function prod\n",
    "    @objective(m,Min,lambda*delta+ dot(weights,S+prod.(Z,n)))\n",
    "    status = solve(m)\n",
    "    loss= getobjectivevalue(m)\n",
    "    return(loss)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learnGraph (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds the matrix A which minimices the expected error of cluster structure. This\n",
    "#time, A is a simmtric entrywise-positive matrix.\n",
    "#The parameters are the same as in learnError function\n",
    "function learnGraph(weights,delta,B,n,N)\n",
    "    one =ones(n)\n",
    "    m = Model(solver=MosekSolver())\n",
    "    @variable(m,lambda>=0)\n",
    "     @variable(m,S[1:N])\n",
    "    @variable(m, W[1:n,1:n], Symmetric)\n",
    "    @variable(m,A[1:n,1:n], Symmetric)\n",
    "    Z = [@variable(m, [1:n, 1:n], Symmetric) for p in 1:N]\n",
    "    C = [@variable(m, [1:n, 1:n], Symmetric) for p in 1:N]\n",
    "    @variable(m,W1[1:n,1:n])\n",
    "    @variable(m,W2[1:n,1:n])\n",
    "    #Constraints for Z\n",
    "    [@constraint(m, -Z[p][k,l] <= A[k,l]-B[p][k,l]) for p in 1:N for k in 1:n for l in 1:n]\n",
    "    [@constraint(m,  A[k,l]-B[p][k,l]<=Z[p][k,l]) for p in 1:N for k in 1:n for l in 1:n]\n",
    "    #Constraints for C \n",
    "    [@constraint(m,C[p][k,l]>=0)for p in 1:N for k in 1:n for l in 1:n]\n",
    "    [@constraint(m, prod(C[p],n)<=S[p]-trace((2*A-one*one'-W)'*B[p])) for p in 1:N]\n",
    "    [@constraint(m,-C[p][k,l]<=2*A[k,l]-1-W[k,l])for p in 1:N for k in 1:n for l in 1:n]\n",
    "    #Constraints for W\n",
    "    @SDconstraint(m,[W1 W;W W2]>=0)\n",
    "    @constraint(m,trace(W1)+trace(W2)<=2*lambda)\n",
    "    #constrains for A\n",
    "    [@constraint(m,A[k,l]>=0) for k in 1:n for l in 1:n]\n",
    "    [@constraint(m,A[k,l]<=1) for k in 1:n for l in 1:n]\n",
    "    #Objective function, calls the function prod\n",
    "    @objective(m,Min,lambda*delta+ dot(weights,S+prod.(Z,n)))\n",
    "    status = solve(m)\n",
    "    return([roundZeroMatrix(getvalue(A)),getvalue(S),getvalue(lambda),roundZeroMatrix(getvalue(W)),getobjectivevalue(m)])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Funciones auxiliares <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "erdosgraph (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aux functions\n",
    "#def function prod computes the product 1^t*Z*t.\n",
    "#@param: n : the dimension of the matrices.\n",
    "function prod(Z,n)\n",
    "    return(ones(n)'*Z*ones(n))\n",
    "end\n",
    "\n",
    "#def function roundMatrix applies the function roundZero to every element of the matrix.\n",
    "#@param: A : matrix to round\n",
    "function roundZeroMatrix(A)\n",
    "    map(A) do x\n",
    "        roundZero(x)\n",
    "    end\n",
    "end\n",
    "\n",
    "#def function roundZero rounds close reals to zero to zero\n",
    "function roundZero(a)\n",
    "    if(abs(a)<=0.0001)\n",
    "        return(0)\n",
    "    end\n",
    "    return(a) \n",
    "end\n",
    "\n",
    "#def function nuclearNorm Computes the nuclear norm of a matrix\n",
    "#@param mat : mat to compute the nuclear norm\n",
    "function nuclearNorm(mat)\n",
    "    return(sum(svdfact(mat)[:S]))\n",
    "end\n",
    "\n",
    "#function which computes the estimation of the error as by theorem 3.1\n",
    "#@param delta: radius of the wasserstein metric ball.\n",
    "#@param A : solution of the optimization problem.\n",
    "#@param B : Array of the observation matrix\n",
    "#@param N : numero de observaciones\n",
    "#@param n : dimension de las matrices\n",
    "function estimarCota(delta,A,B,N,n)\n",
    "    a = delta*nuclearNorm(2*A-ones(n)*ones(n)')\n",
    "    [B[i] = A-B[i] for i in 1:N]\n",
    "    d = (1/N)*sum(norm1.(B))\n",
    "    return(a+d)\n",
    "end\n",
    "#function that computes the norm1 of a matrix. note that the norm(,1) implemented\n",
    "#in julia is the induced 1 norm.\n",
    "#@param W: a matrix\n",
    "function norm1(W)\n",
    "    a= 0\n",
    "    map(W) do x\n",
    "        a = abs(x)+a\n",
    "    end\n",
    "    return(a)\n",
    "end\n",
    "\n",
    "#function to generate a random Erdos-renyi graph with a given number of \n",
    "# clusters and probabilities. Creates an inferior triangluar matrix and then sums its transpose.\n",
    "#@param: probabilities: vector of probabilities>0.5 of each intracluster probability.\n",
    "#The size of the vector is the number of clusters. min(probabilities)>1/2\n",
    "#@param: sizes : the sizes of the clusters.\n",
    "#@param: n : the dimension of the adjacency matrix.\n",
    "#@param: q : outercluster adjacency probability : q<1/2\n",
    "#@Pre: the sum of the sizes must be n.\n",
    "function erdosgraph(probabilities,q,sizes,n)\n",
    "    A= zeros(n,n)\n",
    "    contador2=0\n",
    "    proba = 1\n",
    "    contador1=1\n",
    "    for k in sizes\n",
    "        contador2=contador2+k\n",
    "        for j in contador1:contador2\n",
    "            for i in j+1:n\n",
    "                rand1=rand()\n",
    "                rand2=rand()\n",
    "                if(i>=contador1 && i<=contador2)\n",
    "                    if(rand1<=probabilities[proba])\n",
    "                        A[i,j]=1\n",
    "                    end\n",
    "                else\n",
    "                    if(rand2<=q)\n",
    "                        A[i,j]=1\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        proba=proba+1\n",
    "        contador1=contador1+k\n",
    "    end\n",
    "    return(A+A')\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
